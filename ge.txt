# NEBULA AGENT — agent.md (Design, Prompts & Runbook)

 Ziel Ein lokaler → VPS‑fähiger, sicherer Autopilot‑Agent für das Projekt Nebula Supply (Web + API + Worker), der via MCP (Model Context Protocol) Tools nutzt, Fehler automatisch erkennt, behebt, testet und deployt – mit klaren Prompts, Guard‑Rails und wiederholbaren Playbooks.

---

## 1) Vision & Scope

 Was Full‑stack KI‑Agent, der Aufgaben („Tasks“) für Nebula Supply umsetzt Code schreibenändern, UI verbessern, Bugs fixen, Tests erweitern, Migrations fahren, Deployen.
 Wie LLM + MCP‑Tools (Filesystem, Git, HTTPBrowserPlaywright, SqlitePostgres, Shell (guarded)).
 Wo Erst lokal (100% offline testbar), dann VPS (Docker Compose + CaddyNginx + Let’s Encrypt).
 Warum Geschwindigkeit, Wiederholbarkeit, Sicherheit, Anonymität.

Nicht‑Ziele Offene Shell ohne Safeguards, heimliche Telemetrie, unkontrollierte Internet‑Schreibzugriffe.

---

## 2) Architektur (High‑Level)

```
┌────────────┐        ┌──────────────┐        ┌──────────────┐
│  ChatGPT   │  MCP   │  Nebula CLI  │  API   │   Services   │
│  (Code)    ├────────►  (Agent)     ├────────►  WebAPIDB  │
└────────────┘        └──────────────┘        └──────────────┘
       ▲                       │  ▲                     │
       │                       │  │                     │
       │                  ┌────┘  └─────┐         ┌─────▼────┐
       │                  │ Autofix Loop │         │  DBCache│
       │                  └──────────────┘         └──────────┘
       │  MCP Servers fs, git, http, playwright, sqlite, shell(guarded)
```

---

## 3) Repos & Struktur (empfohlen)

```
nebula
  apps
    web            # ReactVite (oder Next.js)
    server         # ExpressFastify + Drizzle ORM
    worker         # BullMQQueuesCRON
  packages
    shared         # ZodTypesDrizzle schema
  mcp
    servers        # MCP server wrappersconfigs
  infra
    docker         # compose.yml, Dockerfiles
    caddy          # Caddyfile (oder nginx)
    scripts        # bootstrap, backup, restore
  tests
    e2e            # Playwright
    api            # SupertestVitest
  .env.example
```

---

## 4) Sicherheit & Privacy

 Principle of Least Privilege MCP‑Server nur auf allowlist‑Pfade; Shell‑Kommandos nur vordefiniert (z.B. `npm run ...`, `pnpm ...`, `git ...`, `drizzle-kit ...`).
 Secret‑Handling `.env` lokal, im Repo nur `.env.example`. Für VPS `.env` via Docker secrets oder CaddyEnv‑Files. Optional SOPS + age.
 Anonymität Git‑Identity mit noreply, DoHHTTPS Proxies, Caddy vor Origin, optional Cloudflare.
 AuditLogs Anonymisierte Logs, keine PII; Rotations‑Policy.

---

## 5) Local Quickstart

Voraussetzungen Node 20+, pnpm, Docker, Docker Compose, Git, Playwright deps (chromium install).

```bash
# 1) Repo
git clone httpsgithub.comnebulausernameNebula.git nebula
cd nebula

# 2) Bootstrap
pnpm i
cp .env.example .env    # Secrets füllen
pnpm -w run prepare     # husky etc., optional

# 3) Dev
pnpm --filter @nebulaserver dev
pnpm --filter @nebulaweb dev

# 4) Tests
pnpm test
pnpm exec playwright install --with-deps
pnpm -w run teste2e
```

---

## 6) MCP Setup (Client & Server)

Ziel ChatGPT (Code‑Modus) spricht über MCP mit lokalen Tools.

### 6.1 Beispiel‑Konfiguration (Client‑seitig)

 Lege eine MCP‑Konfiguration an (z.B. `~.configmcpnebula.json`). Die genaue Einbindung hängt von deinem Chat‑Client ab. Inhalt als Ausgangspunkt

```json
{
  servers {
    fs {
      command node,
      args [mcpserversfs.js],
      env {ALLOW .apps,.packages,.tests}
    },
    git {
      command node,
      args [mcpserversgit.js],
      env {GIT_SAFE 1}
    },
    http {
      command node,
      args [mcpservershttp.js]
    },
    playwright {
      command node,
      args [mcpserversplaywright.js]
    },
    sqlite {
      command node,
      args [mcpserverssqlite.js],
      env {DB_PATH ..localnebula.sqlite}
    },
    shell_guarded {
      command node,
      args [mcpserversshell-guarded.js],
      env {ALLOW_CMDS pnpm,git,drizzle-kit,tsc,eslint,vitest,playwright}
    }
  }
}
```

### 6.2 Server‑Skeletons (Node, pseudo)

`mcpserversshell-guarded.js`

```js
import { createServer } from @modelcontextprotocolsdk;
import { spawn } from nodechild_process;

const ALLOW = (process.env.ALLOW_CMDS  ).split(,);
const server = await createServer({ name shell-guarded });

server.tool(run, {
  description Run a whitelisted command,
  inputSchema {
    type object,
    properties { cmd { type string }, args { type array, items { type string } } },
    required [cmd]
  }
}, async ({ cmd, args = [] }) = {
  if (!ALLOW.includes(cmd)) return { error `Command not allowed ${cmd}` };
  return await new Promise((resolve) = {
    const p = spawn(cmd, args, { cwd process.cwd() });
    let out = , err = ;
    p.stdout.on(data, d = out += d.toString());
    p.stderr.on(data, d = err += d.toString());
    p.on(close, code = resolve({ code, out, err }));
  });
});

server.start();
```

 Analoge, einfache Server für `fs` (readwrite mit Allowlist), `git` (status, diff, commit), `http` (GET), `playwright` (open, screenshot, assert), `sqlite` (queryexec).

---

## 7) Autofix‑Loop (Agent Execution)

Ziel Task → Plan → Apply Patch → Tests → Feedback → Iterate (N‑mal) → PRCommit.

Pseudocode (CLI `nebulainfrascriptsagent.ts`)

```ts
for (let i=0; iMAX_ITERS; i++) {
  const plan = await llm.plan(task, contextFromRepo());
  const patch = await llm.edit(plan, filesSubset());
  await fs.applyPatch(patch);
  const result = await shell.run(pnpm, [-w,testci]);
  if (result.code === 0) break;
  const analysis = await llm.errorAnalysis(result.out + result.err);
  task = task + nFix  + analysis.nextSteps;
}
await git.commitAndPush(feat(agent) +summarize(task));
```

Tests in CI `tsc --noEmit`, `eslint`, `vitest`, `playwright` (headless), API smoke via Supertest.

---

## 8) Master‑Prompts (für ChatGPT Code  „Codex“)

 Hinweis Diese Prompts sind so entworfen, dass du sie 11 in einen neuen Chat einfügst. Danach arbeitest du mit den Task‑Prompts.

### 8.1 System  Initial Context (einmalig)

```
Du bist mein Nebula Supply Build‑Agent. Ziele Code‑Qualität, Sicherheit, Anonymität, Reproduzierbarkeit. Nutze MCP Tools (fs, git, http, playwright, sqlite, shell_guarded) strikt gemäß Allowlist. Vorgehen bei jeder Aufgabe
1) Verstehe Kontext (Repo‑Map, package.json scripts, env‑Bedarf).
2) Erstelle einen Plan mit minimal‑invasiven Änderungen und Backout‑Strategie.
3) Arbeite in kleinen Patches (diffs), jeweils mit Tests und Lint.
4) Führe `pnpm -w testci` aus. Wenn Fehler analysiere Logs, improve Patch, wiederhole.
5) Erzeuge Commit‑Message nach Conventional Commits.
6) Dokumentiere Änderungen in `CHANGELOG.md` und `agent-report.md`.
Guard‑Rails Keine Secrets ausgeben; nur Allow‑Commands; keine PII in Logs.
```

### 8.2 Task‑Prompt Vorlage

```
TASK konkrete Aufgabe
CONSTRAINTS Erhalte Architektur; ändere nur betroffene Module; 100% Tests grün.
DELIVERABLES Git‑Diff, Test‑Ergebnisse, kurze Doku.
RUN Führe nacheinander `tsc`, `eslint`, `vitest`, `playwright`, `supertest` via `pnpm -w testci`.
```

### 8.3 Bugfix‑Prompt

```
BUG Fehlerbeschreibung + Logs
Erzeuge minimalen Patch mit Repro‑Test. Nutze `playwright` für E2E wenn UI betrofffen.
```

### 8.4 UI‑Polish Prompt

```
Verbessere UI gemäß Design‑Screenshots (Spacing, Typografie, Responsiveness). Nutze Tailwind, shadcnui. Keine Breaking Changes in API. Erzeuge visuelle Snapshots mit Playwright.
```

### 8.5 DatenmodellMigration Prompt

```
Ändere Drizzle Schema + Migration. Bewahre Backward Compatibility. Schreibe Datenmigrations‑Script und Rollback. Aktualisiere Zod‑Schemas + API‑DTOs + Tests.
```

### 8.6 Commit‑Message Prompt

```
Erzeuge eine prägnante Conventional‑Commit Message + Body + BREAKING CHANGE (falls nötig) basierend auf dem Diff.
```

---

## 9) Git‑Workflow (einfach)

 Branches `main` (stabil), `dev` (Integration), `featname` (Feature), `fixname` (Hotfix).
 Regeln PRs in `dev` → CI grün → Merge → Release‑Tag → `main`.
 Hooks pre‑commit (lint-staged), pre‑push (testquick), CI Gates (testci, build, e2e).

---

## 10) Tests & QA

 Unit Vitest + @testing-library.
 API Supertest gegen Express.
 E2E Playwright (headless), Snapshots, Axe‑Accessibility Check.
 Smoke `apihealth` muss 200 liefern.

---

## 11) Deployment (VPS)

Basis Ubuntu 24.04 LTS, Docker, Compose, Caddy (oder Nginx) + Let’s Encrypt.

### 11.1 Docker Compose (minimal)

`infradockercompose.yml`

```yaml
services
  web
    build ....
    command pnpm -w run startweb
    env_file .....env
    depends_on [api]
    ports [127.0.0.151735173]
  api
    build ....
    command pnpm -w run startserver
    env_file .....env
    ports [127.0.0.150005000]
  caddy
    image caddylatest
    volumes
      - ..caddyCaddyfileetccaddyCaddyfile
    ports
      - 8080
      - 443443
    depends_on [web, api]
```

### 11.2 Caddyfile (TLS + Reverse Proxy)

`infracaddyCaddyfile`

```
example.com {
  encode gzip
  handle_path api {
    reverse_proxy 127.0.0.15000
  }
  handle {
    reverse_proxy 127.0.0.15173
  }
  log {
    output file varlogcaddynebula.log
    format json
  }
}
```

### 11.3 CI (GitHub Actions, minimal)

`.githubworkflowsci.yml`

```yaml
name ci
on [push, pull_request]
jobs
  build
    runs-on ubuntu-latest
    steps
      - uses actionscheckout@v4
      - uses pnpmaction-setup@v3
        with { version 9 }
      - uses actionssetup-node@v4
        with { node-version 20 }
      - run pnpm i
      - run pnpm -w run testci
```

---

## 12) Ops‑Runbooks

 Backup DB `pg_dump $DATABASE_URL  backups$(date +%F).sql` (oder `sqlite .dump`).
 Restore `psql  dump.sql`.
 Secrets rotieren neue `.env`, `docker compose up -d --force-recreate`.
 Zero‑Downtime BlueGreen via `compose -p nebula_a``nebula_b` + Caddy switch.

---

## 13) Observability

 Logs pinohttp + JSON; Rotation via `logrotate`.
 Metrics Prometheus endpoint `metrics` + Grafana optional.
 Tracing OpenTelemetry SDK (HTTP serverclient).

---

## 14) Checklisten

### Day‑0 (Lokal)

 [ ] Repo clean, `pnpm i`, `pnpm -w testci` grün
 [ ] MCP‑Servers laufen, Allowlist verifiziert
 [ ] Agent‑Loop lokal patcht & committet

### Day‑1 (VPS)

 [ ] VPS härten (ufw, fail2ban), DockerCompose
 [ ] Caddy TLS + Reverse Proxy ok
 [ ] Health‑Checks grün

### Day‑2 (Scale)

 [ ] WorkerQueues bereit
 [ ] Alerts (uptime, error‑rate)

---

## 15) `.env.example` (Auszug)

```
# Server
PORT=5000
NODE_ENV=production
# DB
DATABASE_URL=postgresuserpass@host5432nebula
# AuthSecrets
SESSION_SECRET=change-me
# Playwright
HEADLESS=true
```

---

## 16) package.json Scripts (Vorschlag)

```
{
  scripts {
    dev pnpm -w --parallel -r run dev,
    build pnpm -w -r run build,
    startweb node appswebdistserver.js,
    startserver node appsserverdistindex.js,
    testci tsc -b && eslint . && vitest run --reporter=dot && playwright test,
    lint eslint .,
    typecheck tsc -b,
    e2e playwright test
  }
}
```

---

## 17) Nächste Schritte (empfohlen)

1. Master‑Prompt (8.1) im Code‑Chat setzen.
2. MCP‑Server starten und via Client verbinden.
3. Task „Baue Autofix‑Loop + agent CLI“.
4. Task „Richte CI + Playwright + API smoke tests ein“.
5. Task „Dockerize + Caddy Reverse Proxy“.
6. Task „VPS‑Deploy mit .env + Secrets“.

 Dieses Dokument ist die Single‑Source‑of‑Truth für Agent‑Arbeitsweise, Prompts, und Ops.

---

## 18) Produkt- & UX‑Flows (aus deiner Demo, präzisiert)

Onboarding Sprache (DEEN) → Nickname → Profil (Rang, Coins, Invites, Bestellungen). Regeln max. 1 StornoWoche, 30‑Minuten‑Storno‑Fenster, Adressabfrage erst nach Zahlung.

HauptmenüWebView `Home  Shop  Drops  Top  Profil` mit Filterleiste (Geschmack, Preis, Menge). Live‑Daten via WebSocket.

Drop‑Ansicht Name, Drop‑Preis, Straßenpreis, Mindest‑Preorder, Fortschritt (PreordersMindestmenge + Balken), Sortenliste, Buttons Interesse, Preorder, Ganze Menge bestellen.

Preorder‑Flow Warnung (verbindlich, 30‑Minuten‑Storno). Auswahl MengeSorten → Bestätigung → Timer startet → nach 30 Min keine Stornierung. Storno‑Limit 1WocheUser.

Erinnerungen Push bei 50 % und 90 % Progress; optional Drop endet in 2 h.

Bezahlung BTC (QR, Amount, Auto‑Watcher), Voucher (Code prüfen), Barzahlung (Selfie + Admin‑Freigabe; wenn nicht eingeladen, Selfie Pflicht).

Nach Zahlung Adressformular → Profil aktualisieren (Bestellungen, Coins) → Admin‑Sicht erhält Kunden‑Order + Adresse.

Coin‑Shop (sichtbar als Rewards, Regeln im Backend erzwungen)

 50 Coins → 5 € Rabatt (Mindestbestellwert 15 €)
 100 Coins → 10 € Rabatt (Mindestbestellwert 30 €)
 Cap höchstens 20 € Rabatt pro Bestellung (Mindestbestellwert ≥ 30 €)
 5 % Coins auf Subtotal; fix +100 Coins pro Preorder (Belohnung intern, für Nutzer nicht prominent anzeigen)

Leaderboard Top Inviter (1–5), Top Käufer (1–3), Top Coins (1–5) – Live via WebSocket, Admin kann Promo‑Fake‑Einträge togglen (Flag in Admin‑UI, Kennzeichnung intern).

Ticket‑System `ticket` → Thema + Nachricht; Admin‑Queue mit Status [Bearbeitet][Schließen].

Admin‑Panel `adddrop`, `editdrop id`, `removedrop id`, `fakedrop`, `faketop`.

---

## 19) Domain‑Modell & DB (DrizzleSQL, Vorschlag)

User(id, nickname, lang, rank, invited_by, selfie_url, bans, weekly_cancels_count, created_at)

Wallet(user_id FK, coins INT DEFAULT 0, lifetime_coins INT)

Drop(id, name, price_drop DECIMAL, price_street DECIMAL, min_qty INT, status ENUM('draft','live','locked','done'), assortments JSONB, created_at, promo_fake BOOL DEFAULT false)

Preorder(id, user_id FK, drop_id FK, items JSONB[{flavor,qty}], qty_total INT, status ENUM('pending','locked','cancelled','paid','fulfilled'), created_at, lock_at)

Payment(id, preorder_id FK, method ENUM('btc','voucher','cash'), amount DECIMAL, tx_ref, status ENUM('pending','confirmed','failed'), confirmed_at)

Order(id, user_id, drop_id, items JSONB, total DECIMAL, address JSONB, status ENUM('processing','shipped','delivered'))

Voucher(code UNIQUE, value_eur DECIMAL, min_subtotal DECIMAL, active BOOL, used_by USER_ID NULL)

LeaderboardSnapshot(id, kind ENUM('invites','buyers','coins'), payload JSONB, created_at)

Ticket(id, user_id, topic, message, status ENUM('open','done'), created_at, updated_at)

Rules(id, key, value JSONB)  # z.B. Rabatt‑Caps, Storno‑Fenster, Coin‑Raten

 Indizes (user_id), (drop_id,status), (created_at DESC). Constraints für CapsRegeln über DB CHECKs + Service‑Layer.

---

## 20) API‑Endpoints (ExpressFastify, Auszug)

Public

 `GET apidrops` (list live, progress, flavors)
 `GET apidropsid` (detail)
 `POST apipreorders` (create; body drop_id, items)
 `POST apipreordersidcancel` (innerh. 30 Min & 1Woche)
 `POST apipaymentspreorderId` (method btcvouchercash)
 `POST apipaymentsidconfirm` (webhookwatcher)
 `POST apiaddress` (nach Zahlung)
 `GET apiprofile` (orders, coins)
 `GET apileaderboard`
 `POST apitickets`

Admin (token‑geschützt)

 `POST apiadmindrop` (add)
 `PATCH apiadmindropid` (edit)
 `DELETE apiadmindropid` (remove)
 `POST apiadminfakedrop` (toggle)
 `POST apiadminfaketop` (toggle)

System

 `GET apihealth` (200)
 `GET apimetrics` (Prometheus)

---

## 21) Bot‑Flows (Telegram, aiogramTelegraf)

 `start` → Begrüßung + Sprache → Profil anlegen
 `shop`, `drops`, `top`, `profile`, `ticket`
 Drop‑Detail via Deep‑Link → WebView URL mit Signatur (user_id, nonce)
 Admin‑Commands `adddrop`, `editdrop`, `removedrop`, `fakedrop`, `faketop`, `info @user`

---

## 22) Coins & Discounts (Server‑Regeln)

 Earn `+100` Coins pro Preorder (fix). Zusätzlich `ceil(subtotal  0.05)` Coins.
 Burn Einlösen nur in vordefinierten Staffeln (5€, 10€, 20€ Cap pro Bestellung). Mindestbestellwerte erzwingen.
 Sichtbarkeit Coins‑Stand anzeigen; intern Bonus‑Logik, keine manipulierbaren Client‑Checks.
 Anti‑Abuse Keine Coins bei StornoChargeback; rückwirkende Abzüge möglich.

---

## 23) Notifications & Scheduler

 Jobs 50 %90 % Fortschritt → Push; Drop endet in 2 h; Payment‑Watcher (BTC); Storno‑Timer nach 30 Min → Preorder locken.
 Queue BullMQ mit Redis; idempotente Jobs, Dead‑Letter Queue; retrybackoff.

---

## 24) Sicherheit, Rate‑Limits, Privacy

 Admin‑API tokenisiert, IP‑Allowlist optional. Rate‑Limits per IPUser (login, preorder, payment).
 Cash‑Zahlung Selfie Pflicht bei fehlender Einladung. Medien‑Storage mit signierten URLs. DSGVO Minimierte Daten, Lösch‑Routine, Consent im Onboarding.

---

## 25) Admin‑Panel (Web + Bot)

 Drop CRUD, Fake‑Toggles (mit Audit Log), Übersicht PaymentsPreorders, Ticket‑Queue, Leaderboard‑Preview, Regel‑Editor für CapsTimer.

---

## 26) Implementation Roadmap (Step‑by‑Step)

1. Repo‑Cleanup & Monorepo Struktur (apps, packages, infra, mcp)
2. DB & Models (Drizzle schema + migrations + seeds)
3. Public API (drops, preorder, payments, profile)
4. CoinsRules Engine (Caps, Mindestwerte, 5% earn, +100 fix)
5. Bot (Commands, WebView Sign‑Links)
6. WebView (Drop‑Detail, Progressbar, Preorder UI, Checkout)
7. Payments (BTC watcher, Voucher, Cash‑Flow mit Selfie‑Review)
8. Notifications (BullMQ + Redis, 5090% + Endtimer)
9. Admin‑Panel (CRUD, Fakes, Tickets, Leaderboard)
10. QA & CI (unitapie2e, accessibility, smoke)
11. Docker & VPS (compose + Caddy)

---

## 27) Schritt‑Prompts (für Codex)

A. Repo‑Cleanup & Skeleton

```
TASK Richte die Monorepo‑Struktur (appsweb, appsserver, packagesshared, infra, mcp, tests) ein, überführe bestehenden Code minimalinvasiv. Füge Scripts aus agent.md §16 hinzu. Ziel `pnpm -w testci` grün.
```

B. DB‑Schema + Migrationen

```
TASK Implementiere Drizzle‑Schemas gemäß agent.md §19 und generiere Migrationen. Schreibe Seeds für Demo‑Drop und zwei User. Liefere SQL + Type‑Safety Tests.
```

C. Public API

```
TASK Baue Endpoints aus §20 (public) inkl. Zod‑DTOs, Fehlercodes, Supertest‑Specs. Health‑Check muss 200 liefern.
```

D. CoinsRules

```
TASK Implementiere Coins‑EarnBurn und Rabatt‑Caps exakt wie in §22, inkl. Unit‑Tests für Edge Cases.
```

E. Bot + WebView

```
TASK Telegram‑Bot mit Commands aus §21, WebView‑Signaturen, Drop‑Detail‑Linking, E2E‑Tests mit Playwright Screenshots.
```

F. Payments + Watcher

```
TASK BTC‑Watcher (MockAdapter), Voucher‑Prüfung, Cash‑Flow (Selfie + Admin Approve). Webhooks & Status‑Transitions testen.
```

G. Notifications

```
TASK BullMQ‑Jobs (5090% Push, Endtimer, Storno‑Lock), RetryBackoff, Idempotenz‑Keys, Tests.
```

H. Admin‑Panel

```
TASK CRUD UI, Toggle‑Flags, Ticket‑Queue, Leaderboard‑Preview. Access‑Guards + Audit‑Log.
```

---

## 28) Compliance & Risiken (Kurz)

 Nutzeridentität nur, wenn nötig (Cash). Keine unverifizierten Marketing‑Fake‑Statistiken öffentlich kennzeichnen. Zahlungsdaten minimal halten. Logs ohne PII. DSGVO‑Rechte umsetzen (ExportLöschung).
